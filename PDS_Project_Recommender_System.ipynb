{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qQPMQypMgIB"
   },
   "source": [
    "# Can Contents Improve Movie Recommendations?\n",
    "\n",
    "Recommender systems are widely used today to recommend movies, music, news and all kinds of products to website users. In this project, we built three different types of different movie recommender systems and also evaluated their performance. This project focused on how contents of movies can improve the result of the movie recommendation. The content of the project is listed as following:  \n",
    "\n",
    "- Why Content-Based Recommender\n",
    "- Preparing the Data\n",
    "    - Feature Selection\n",
    "- Building Collaborative Filtering Recommender\n",
    "- Building Content-Based Recommender\n",
    "- Building Hybrid Recommender\n",
    "    - Introduction of Recommender\n",
    "    - Data Pre-Processing\n",
    "    - Model Training\n",
    "- Recommender Evaluation\n",
    "- Results and Conclusions\n",
    "- Additional (Interesting) Facts\n",
    "- Citation\n",
    "- Appendix\n",
    "\n",
    "## Why Content-Based Recommender\n",
    "In one of the class assignment we built a movie recommender using collaborative filtering (CF). It takes the interaction matrix, which consists the records of the ratings of movies by every user. One interesting fact or disadvantage of CF is that it only uses users' ratings as input. This means no matter what you are recommending, such as movies, songs or news, you always use the same method for different products. The intrinsic facts of products, such as the director of the movie or the singer of the song,  are not used in CF. We would like to discover how these intrinsic facts can be used in recommending. \n",
    "\n",
    "Collaborative filtering also has has limitations in application. It works well when you have lots of data and the utility matrix is dense. However, it works poorly when the utility matrix is sparse, which could be the case of large product inventory, short-lived products and lots of new users [1]. In those cases, CF performs poorly because many items are rated by users and most users do not rate any items. Content based recommender overcomes this shortcoming. Even if you only have the record of one user buying one item, based on the characteristic (content) of the item, we can recommender similar items to that user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11840,
     "status": "ok",
     "timestamp": 1526072703013,
     "user": {
      "displayName": "Xiang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111719387879022018839"
     },
     "user_tz": 240
    },
    "id": "2bssVkQqNQ8g",
    "outputId": "cb0b420a-809f-4729-ea92-53afc6a28be0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q xlrd\n",
    "# !pip install lightfm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data \n",
    "\n",
    "In our project, we mainly made use of two types of data: \n",
    "\n",
    "![](data_intro.jpeg)\n",
    "\n",
    "1. Ratings records of a user toward different movies he / she has ever watched and rated\n",
    "2. Movie's attributes including actors, director & screenplay, and summaries\n",
    "\n",
    "The following parts will give a brief introduction of our steps of data preparation.\n",
    "\n",
    "### Data Sources\n",
    "\n",
    "We collected our data from two sources:\n",
    "\n",
    "1. The ratings records comes from [the MovieLens Dataset](https://grouplens.org/datasets/movielens/). The dataset is pre-processed and stored in `.csv` format.\n",
    "2. The movies' attributes are scraped from [the Movie Database](https://www.themoviedb.org/?language=en). A sample screenshot of this website is given below:\n",
    "\n",
    "![](data_scrape_source.jpeg)\n",
    "\n",
    "### Data Scraping\n",
    "\n",
    "Given a filtered list of valid movie ids, we scraped the original htmls of each movie and then extracted selected features from them.\n",
    "\n",
    "Core code blocks are presented below. To run the code from scratch, the complete scripts can be found in the **appendix** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {}\n",
    "error_log = []\n",
    "\n",
    "mov_TMDB_id_list = mov_TMDB_df[\"tmdbId\"]\n",
    "mov_TMDB_err_list = []\n",
    "\n",
    "# scraping original html\n",
    "\n",
    "counter = 0\n",
    "for tmdb_id in mov_TMDB_id_list:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(\"[PROGRESS] {} / {}\".format(counter, len(mov_TMDB_id_list)))\n",
    "\n",
    "    url = \"https://www.themoviedb.org/movie/\" + tmdb_id\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"    [ERROR LOG] TMDB_ID: {}, Response Code: {}. Drop.\".format(tmdb_id, response.status_code))\n",
    "        error_log.append(\"TMDB_ID: {}, Response Code: {}. Drop.\".format(tmdb_id, response.status_code))\n",
    "        mov_TMDB_err_list.append(tmdb_id)\n",
    "    else:\n",
    "        response_dict[tmdb_id] = response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we get the html text for each movie, we parse the text and extract selected information from them. We will talk about feature selection right after. Again we only present the core code block here. The complete script can be found in the **appendix** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_content = []\n",
    "mov_TMDB_final_list = []\n",
    "\n",
    "counter = 0\n",
    "for tmdb_id in mov_TMDB_valid_list:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(\"[PROGRESS] {} / {}\".format(counter, len(mov_TMDB_valid_list)))\n",
    "\n",
    "    try:\n",
    "        html_text = response_dict[tmdb_id].text\n",
    "        root = BeautifulSoup(html_text, \"html.parser\")\n",
    "        mov_name = root.find(\"div\", class_=\"title\").span.a.h2.string\n",
    "\n",
    "        mov_lang = \"\"\n",
    "        mov_genres = []\n",
    "        mov_keywords = []\n",
    "        mov_crew = []\n",
    "        mov_actors = []\n",
    "        mov_infos = []\n",
    "\n",
    "        mov_facts = root.find(\"section\", class_=\"facts\").find_all(\"p\")\n",
    "        for fact in mov_facts:\n",
    "            if fact.bdi != None and fact.bdi.string == \"Original Language\":\n",
    "                mov_lang = re.sub(r\"[,.;@#?!&$ ]+\", \"_\", fact.contents[1].strip().lower())\n",
    "                mov_infos.append(mov_lang)\n",
    "\n",
    "        mov_genres_section = root.find(\"section\", class_=\"genres\").find_all(\"li\")\n",
    "        for genre in mov_genres_section:\n",
    "            mov_genres.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", genre.a.string.strip().lower()))\n",
    "        mov_infos.extend(mov_genres)\n",
    "\n",
    "        mov_keywords_section = root.find(\"section\", class_=\"keywords\").find_all(\"li\")\n",
    "        for keyword in mov_keywords_section:\n",
    "            mov_keywords.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", keyword.a.string.strip().lower()))\n",
    "        mov_infos.extend(mov_keywords)\n",
    "\n",
    "        mov_people_list = root.find(\"div\", class_=\"header_info\").find(\"ol\", class_=\"people\").find_all(\"a\")\n",
    "        for people in mov_people_list:\n",
    "            mov_crew.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", people.string.strip().lower()))\n",
    "        mov_infos.extend(mov_crew)\n",
    "\n",
    "        mov_actor_list = root.find(\"section\", class_=\"top_billed\").find_all(\"li\")\n",
    "        for actor in mov_actor_list:\n",
    "            mov_actors.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", actor.p.a.string.strip().lower()))\n",
    "        mov_infos.extend(mov_actors)\n",
    "\n",
    "        movie_content.append(\" \".join(mov_infos))\n",
    "        mov_TMDB_final_list.append(tmdb_id)\n",
    "    except:\n",
    "        print(\"    [ERROR LOG] TMDB_ID: {}, unable to parse. Drop.\".format(tmdb_id))\n",
    "        mov_TMDB_err_list.append(tmdb_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "An essential part of our project is to decide which features to use to encode a movie. After careful reasoning and experiments, we chose `actors`, `crews` (director, screenplay, story...), `language`, and `summaries` as our standard features of a movie. \n",
    "\n",
    "`Actors` and `crews` are selected because these information typically has great influences on people's decision about whether to watch a movie or not. People tend to have their favorite actors and directors, and they don't want to miss any movie from those favored movie stars.\n",
    "\n",
    "`Language` tends to be an interesting feature. After `tfidf`, the most frequent value of this feature - 'English' - has limited influence towards our prediction. Other values, however, will pop out if one user watched and highly rated movies with a certain foreign language, e.g., French. In this case, our recommender will tend to recommend movies in French because of this essential feature.\n",
    "\n",
    "`summaries` are keywords and genres of a movie, which shows some basic characteristic of this movie. We treated summaries as a bag of keywords so that similar movies are easier to be found as 'close' in the feature space.\n",
    "\n",
    "### Data Processing\n",
    "\n",
    "After the raw data is ready, we then applied `one-hot encoding`, `tfidf` and `normalization` towards our dataset to get the standard input matrices specified in the **Building Content Based Recommender** section. The matrices we used in our example code are in the following shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1526072718095,
     "user": {
      "displayName": "Xiang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111719387879022018839"
     },
     "user_tz": 240
    },
    "id": "ojkZFyMTt-2y",
    "outputId": "e3fa5592-9af9-45b6-fae2-bd82b9ff6f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<671x8954 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 89580 stored elements in COOrdinate format>\n",
      "<671x8954 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9954 stored elements in COOrdinate format>\n",
      "<8954x16674 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 141705 stored elements in Compressed Sparse Row format>\n",
      "8954\n",
      "16674\n"
     ]
    }
   ],
   "source": [
    "interaction_train = scipy.sparse.load_npz('interaction_train.npz')\n",
    "interaction_test = scipy.sparse.load_npz('interaction_test.npz')\n",
    "item_features = scipy.sparse.load_npz('item_features.npz')\n",
    "movie_names = np.load('item_labels.p')\n",
    "movie_features = np.load('item_features_labels.p')\n",
    "\n",
    "print(repr(interaction_train))\n",
    "print(repr(interaction_test))\n",
    "print(repr(item_features))\n",
    "print(len(movie_names))\n",
    "print(len(movie_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKM1mEglizVs"
   },
   "source": [
    "## Building Collaborative Filtering Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QErU-MSat-7N"
   },
   "source": [
    "Our implementation of Collaborative Filtering is identical to what we've built in the assignment. We used matrix factorization to find two lower rank matrix, U and V. U is a matrix of features for each user and V is a matrix of features for each movie. By taking the dot product of the two matrix, we get the original interaction matrix. In this project we used CF as our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "movies = item_features\n",
    "ratings_train = interaction_train.toarray()\n",
    "ratings_test = interaction_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "2hobZgODxLrZ"
   },
   "outputs": [],
   "source": [
    "def error(X, U, V):\n",
    "    \"\"\" Compute the mean error of the observed ratings in X and their estimated values. \n",
    "        Args: \n",
    "            X (numpy 2D array) : a ratings matrix as specified above\n",
    "            U (numpy 2D array) : a matrix of features for each user\n",
    "            V (numpy 2D array) : a matrix of features for each movie\n",
    "        Returns: \n",
    "            (float) : the mean squared error of the observed ratings with their estimated values\n",
    "        \"\"\"\n",
    "    W = X > 0\n",
    "    W = W.astype(np.int)\n",
    "    \n",
    "    X_pred = U @ V.T\n",
    "    error_matrix = W * (X - X_pred)**2\n",
    "    return error_matrix.sum()/W.sum()\n",
    "\n",
    "\n",
    "def CF_train(X, X_te, k, U, V, niters=51, lam=10, verbose=False):\n",
    "    \"\"\" Train a collaborative filtering model. \n",
    "        Args: \n",
    "            X (numpy 2D array) : the training ratings matrix as specified above\n",
    "            X_te (numpy 2D array) : the testing ratings matrix as specified above\n",
    "            k (int) : the number of features use in the CF model\n",
    "            U (numpy 2D array) : an initial matrix of features for each user\n",
    "            V (numpy 2D array) : an initial matrix of features for each movie\n",
    "            niters (int) : number of iterations to run\n",
    "            lam (float) : regularization parameter\n",
    "            verbose (boolean) : verbosity flag for printing useful messages\n",
    "            \n",
    "        Returns:\n",
    "            (U,V) : A pair of the resulting learned matrix factorization\n",
    "    \"\"\"\n",
    "    W = X > 0\n",
    "    W = W.astype(np.int)\n",
    "    \n",
    "    for ii in range(niters):\n",
    "        for i, Wi in enumerate(W):\n",
    "            j_idx = np.nonzero(Wi)[0]\n",
    "            U[i] = np.linalg.solve(np.dot(V[j_idx].T, V[j_idx]) + lam * np.eye(k), np.dot(V[j_idx].T, X[i,j_idx].T))\n",
    "            \n",
    "        for j, Wj in enumerate(W.T):\n",
    "            i_idx = np.nonzero(Wj)[0]\n",
    "            V[j] = np.linalg.solve(np.dot(U[i_idx].T, U[i_idx]) + lam * np.eye(k),\n",
    "                                     np.dot(U[i_idx].T, X[i_idx, j]))\n",
    "#         print('ii', ii)\n",
    "        if (verbose and (ii % 5 == 0)):\n",
    "            print('Iter:', ii)\n",
    "            print('Train Error:', error(X, U, V))\n",
    "            print('Test Error:', error(X_te, U, V))\n",
    "            print('---------------')\n",
    "    \n",
    "    return (U,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fB2RfiscxTjb"
   },
   "outputs": [],
   "source": [
    "# Train CF using k = 5, get trained U and V\n",
    "k = 5\n",
    "init_U = np.ones((ratings_train.shape[0],k))\n",
    "init_V = np.ones((ratings_train.shape[1],k))\n",
    "trained_U,trained_V = CF_train(ratings_train, ratings_test, k, init_U, init_V, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgtkK8KXNAnI"
   },
   "source": [
    "## Building Content Based Recommender\n",
    "The content based recommender uses the characteristics of a movie and a user's previous rating to recommend movies to the users.   \n",
    "The input of this algorithm contains two matrices:  \n",
    "*   A item-features matrix, whose dimension is $n\\times k$. It represents $n$ movies with $k$ features for each movie. \n",
    "*   A user-item interaction matrix, whose dimension is $m \\times n$. It represents $m$ users with their ratings to $n$ movies. \n",
    "\n",
    "The output of this algorithm is a user-feature matrix, whose dimension is $n \\times k$. It can be though as a user-profile matrix. Each user is represented with a $k$ dimensional feature vector.  \n",
    "\n",
    "\n",
    "The algorithm works this way:\n",
    "```\n",
    "For each user:  \n",
    "Element-wise multiply the rating for one movie with the feature vector of the movie. This gives us a new movie-feature matrix ($m \\times k$) for that user.    \n",
    "Sum over all the movies for that user. This returns a $1\\times k$ feature vector for that user.  \n",
    "Calculate the cosine similarity of the user with every movies in the database.  \n",
    "Recommend the top 10 movies that has the greatest cosine similarity.   \n",
    "```\n",
    "Let's use an example to see how this algorithm works intuitively. Suppose we have a user who rated five movies. Three of them is acted by Angelina Jolie and the user likes all the three, so the ratings are positive. Two of them is acted by Robert Downey Jr. and the user dislike the movie, so the ratings are negative. The cosine similarity between the user and movies acted by Jolie would be higher than that between the user and movies acted by Downey.\n",
    "\n",
    "![](algorithm illustration.png)\n",
    "\n",
    "The process of this algorithm is illustrated in the figure above. Using the real dataset, we found that some users tend to give higher scores, while others tend to give lower socores. We standardized ratings for each users by subtracting the mean rating, so that for every user, there are some movies they like a lot and some movies they do not like that much. We only want to recommend the movies that is rated above the user's average. Inspired from nlp and document processing, we also processed the features of the movies using tf-idf, so that common features are lower weighted and unique features are more weighted for the prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aIHyvObQNgTY"
   },
   "outputs": [],
   "source": [
    "def standardize_ratings(ratings):\n",
    "    \"\"\" This function standardizes each row of the inputing matrix by subtracting mean of the row.\n",
    "        Note: when standardizing, only the nonzero elements are counted.\n",
    "    \n",
    "        Args: \n",
    "            ratings (Numpy 2D array m*n) : The original ratings matrix, whose ratings range from 1-5.\n",
    "        \n",
    "        Returns:\n",
    "            (standardized_ratings, num_watched_movie, avg_rating) : dimensions of the returns are (m*n), (m,), (m,) \n",
    "           \n",
    "    \"\"\"\n",
    "    num_watched_movie = np.count_nonzero(ratings, axis=1)\n",
    "    avg_ratings = ratings.sum(axis=1) / num_watched_movie\n",
    "    sdd_ratings = np.subtract(ratings, avg_ratings.reshape(-1,1), where=(ratings!=0))\n",
    "    \n",
    "    return sdd_ratings, num_watched_movie, avg_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "W2YbIuNzXNc3"
   },
   "outputs": [],
   "source": [
    "def build_user_profile(movies, train_ratings):\n",
    "    \"\"\" \n",
    "        This function returns user profile for all the users if the dataset is small.\n",
    "    \"\"\"\n",
    "    num_users = train_ratings.shape[0]\n",
    "    num_movies = train_ratings.shape[1]\n",
    "\n",
    "    num_watched_movies = np.count_nonzero(train_ratings,axis=1).reshape(-1,1)\n",
    "        \n",
    "    if not scipy.sparse.issparse(movies):\n",
    "        movies = np.repeat(movies.reshape(1,movies.shape[0],movies.shape[1]), num_users, axis=0)\n",
    "        train_ratings = train_ratings.reshape(train_ratings.shape[0], -1, 1)\n",
    "\n",
    "        user_profile = (train_ratings * movies).sum(axis=1) / num_watched_movies\n",
    "        \n",
    "        return user_profile\n",
    "    else:\n",
    "        print('movies matrix is not dense')\n",
    "        return None\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4UPj1fTP2Ryp"
   },
   "outputs": [],
   "source": [
    "def get_1user_profile(useridx, ratings_train, movies):\n",
    "    \"\"\"This function build the user profile for one user\"\"\"\n",
    "    user_rating = ratings_train[useridx].reshape(-1,1)\n",
    "    user_profile = movies.multiply(user_rating).sum(axis=0)\n",
    "    return np.array(user_profile)\n",
    "\n",
    "def predict_1user_movies(useridx, movieidx, movies, ratings_train):\n",
    "    \"\"\"This function calculate the the cosine similarity between one user and a list of movies\"\"\"\n",
    "    user_profile = get_1user_profile(useridx, ratings_train, movies)\n",
    "    return cosine_similarity(user_profile, movies[movieidx])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11674,
     "status": "ok",
     "timestamp": 1525915900662,
     "user": {
      "displayName": "Xiang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111719387879022018839"
     },
     "user_tz": 240
    },
    "id": "q-mF8-ImuP6b",
    "outputId": "86c9f719-33f9-464c-e364-7d4108f46139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Movies (Predicted)\n",
      "['Pirates of the Caribbean: The Curse of the Black Pearl (2003)', 'Matrix Reloaded, The (2003)', 'Harry Potter and the Order of the Phoenix (2007)', 'Harry Potter and the Chamber of Secrets (2002)', 'Harry Potter and the Prisoner of Azkaban (2004)', 'Indiana Jones and the Kingdom of the Crystal Skull (2008)', 'Donnie Brasco (1997)', 'E.T. the Extra-Terrestrial (1982)', 'Godfather: Part II, The (1974)', 'V for Vendetta (2006)']\n",
      "Top 10 Movies (Actual)\n",
      "['Iron Man (2008)', 'Dark Knight, The (2008)', 'Sweeney Todd: The Demon Barber of Fleet Street (2007)', 'We Own the Night (2007)', 'Constantine (2005)', 'Million Dollar Baby (2004)', 'Pirates of the Caribbean: The Curse of the Black Pearl (2003)', 'Matrix Reloaded, The (2003)', \"The Devil's Advocate (1997)\", 'Godfather: Part II, The (1974)']\n",
      "Top 5 Movies To recommend\n",
      "['Edge of Darkness (2010)', 'Maria Full of Grace (Maria, Llena eres de gracia) (2004)', 'Harry Potter and the Prisoner of Azkaban (2004)', 'Silence of the Lambs, The (1991)', 'Sweeney Todd: The Demon Barber of Fleet Street (2007)']\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Example User\n",
    "userid = 425\n",
    "watched_movieidx = ratings_train[userid].nonzero()[0]\n",
    "test_movieidx = ratings_test[userid].nonzero()[0]\n",
    "test_movie_names = [movie_names[idx] for idx in test_movieidx]\n",
    "\n",
    "#     print('Watched Movie: ')\n",
    "#     print([movie_names[idx] for idx in watched_movieidx])\n",
    "\n",
    "#     print('Top 10 Features: ')\n",
    "#     user_profile = get_1user_profile(userid, ratings_train, movies)[0]\n",
    "#     print( [movie_features[idx] for idx in np.argsort(user_profile)[::-1][:10]]  )\n",
    "\n",
    "print('Top 10 Movies (Predicted)')\n",
    "rating_pred = predict_1user_movies(userid, test_movieidx, movies, ratings_train)\n",
    "print([movie_names[idx] for rating, idx in sorted(zip(rating_pred, test_movieidx))[::-1][:10]])\n",
    "\n",
    "print('Top 10 Movies (Actual)')\n",
    "rating_true = ratings_test[userid, test_movieidx]\n",
    "print([movie_names[idx] for rating, idx in sorted(zip(rating_true, test_movieidx))[::-1][:10]])\n",
    "\n",
    "print('Top 5 Movies To recommend')\n",
    "rating_reco = predict_1user_movies(userid, range(movies.shape[0]), movies, ratings_train)\n",
    "print([movie_names[idx] for rating, idx in sorted(zip(rating_reco, test_movieidx))[::-1][:5]])\n",
    "print('---------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XqgvU28Ti-ra"
   },
   "source": [
    "## Building Hybrid Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyDNhdI3OGFL"
   },
   "source": [
    "In previous sections, we have seen how to use collaborative filtering and content-based recommender separately to make movie recommendations. In this section, we want to take a step further to see how to integrate these two models together so as to make a more informed decision based on both item features and user-item interactions. \n",
    "\n",
    "More specifically, we would first introduce a hybrid recommendation model called LightFM which brings together the advantages of both CF and CB models. Then, we would make use of this model in our problem setting and evaluate its performance through comparison with the previous two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bS7_TETuUyVK"
   },
   "source": [
    "### Introduction of LightFM\n",
    "\n",
    "LightFM is a hybrid model that combines both content-based recommendation and collaborative filtering methods. Essentially, it generalizes the traditional matrix factorization by jointly factorizing the user-item, item-feature and user-item sparse matrix. \n",
    "\n",
    "Using latent vectors of low dimentionality to represent each variable and summing them together to represent each user and item, this model reduces the number of parameters to estimate and hence becomes much more efficient than traditional methods. This new latent representation of both users and items can also be viewed as \"embeddings\", which can be  correlated with Word2Vec methods. To calculate the similarity between user i and item j, we only need to calculate the dot product of their embeddings. \n",
    "\n",
    "If you are interested in learning more theoretical details about LightFM model, you can refer to the paper [here](https://arxiv.org/pdf/1507.08439.pdf) written by Maciej Kula. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EbGzIjbSPcx"
   },
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n7A4flJjSL2_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interaction_train_fm  <671x8954 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 48764 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing for LigthFM\n",
    "\n",
    "# horizontally stack identity features for per-item feature estimation\n",
    "identity_features = sparse.csr_matrix(np.eye(item_features.shape[0]))\n",
    "item_features_fm = sparse.hstack([item_features, identity_features])\n",
    "\n",
    "# set positive_threshold >0, others considered as zero\n",
    "keep = np.where(interaction_train.data > 0)[0]\n",
    "keep_rows = interaction_train.row[keep]\n",
    "keep_cols = interaction_train.col[keep]\n",
    "interaction_train_fm = sparse.csr_matrix((interaction_train.data[keep], (keep_rows, keep_cols)), shape=interaction_train.shape)\n",
    "print(\"interaction_train_fm \", repr(interaction_train_fm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFG4IqbjSKpG"
   },
   "source": [
    "### Model Training\n",
    "For every pass through the data, the model learns to fit the data more and more closely. We use fit_partial to monitor this incremental learning process and visualize this processing by plotting the train/test precision_at_k metric as below. \n",
    "\n",
    "Precision_at_k is a built-in evaluation metric of LightFM that calculates how many movies from the top k ranked list has shown in known positives (the ones that user has actually rated). We use this metric for now to observe how the model fits the data through iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kCkLjThdI5zN"
   },
   "outputs": [],
   "source": [
    "# instantiate and train the model\n",
    "model = LightFM(loss='warp')\n",
    "num_iters = 20\n",
    "test_precision_at_k = []\n",
    "train_precision_at_k = []\n",
    "for i in range(num_iters):\n",
    "    model.fit_partial(interaction_train_fm, item_features=item_features_fm, epochs=1, num_threads=3)\n",
    "    train_precision_at_k.append(precision_at_k(model, interaction_train_fm, k=10, item_features=item_features_fm).mean())\n",
    "    test_precision_at_k.append(precision_at_k(model, interaction_test, interaction_train_fm, k=10, item_features=item_features_fm).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "UCNfSKnEP4kS"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f715390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the train/test precision at k = 10 for incremental learning\n",
    "plt.plot(np.arange(20), train_precision_at_k, label=\"train_precision_at_k\")\n",
    "plt.plot(np.arange(20), test_precision_at_k,  label=\"test_precision_at_k\")\n",
    "plt.title(\"Train/Test Precision at k = 10\")\n",
    "plt.xticks(np.arange(20))\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Precision_at_k\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUrNrCU3RqNL"
   },
   "source": [
    "We trained the model for 20 iterations with one epoch each time. You can see from the plot above that as the number of iterations increases, the model learns to fit the data better and yields a more precise recommendation strategy.\n",
    "\n",
    "In the next section, we will evaluate LightFM using modified rank correlation score and compare it with pure collaborative filtering and content-based recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZX6gFtZojESE"
   },
   "source": [
    "## Recommender Evaluations\n",
    "### Evaluation Metrics\n",
    "Root mean square error (RMSE) was a popular measurement for recommender systems. It is calculated  by the squre of the difference between a user's real ratings with recommender systems predicted ratings. It requires reommenders' outputs to be real ratings from 1-5 in our case. However, both of our content-based recommender and hybrid recommender's outputs are relative scores from -1 to 1, with 1 means that the user will like the movie with the highest probability. Thus, we created a evaluation metrics to compare the **ranking** between test data (movies) and the output from our recommender.   \n",
    "\n",
    "| Movie   |      Actual Rank      |   Recommended Rank  |\n",
    "|:----------:|:-------------:| : ------ :|\n",
    "|movie1| 1| 1 |\n",
    "|movie2| 2| 4 |\n",
    "|movie3| 3| 2 |\n",
    "|movie4| 4| 3 |\n",
    "|movie5| 5| 5 | \n",
    "\n",
    "One twist of the spearman's rank correlation is that we took the length of the movie list into consideration. This is because the randomness of the test data. In the test data set, the test movies list for some users may contain only 2 movies, while for some other users, the length of the test movie list contains more than 10 movies. We wanted to give recommender a higher score if it can rank 10 movies correctly versus rank 2 movies correctly. Thus the final formula we used for each user is:\n",
    "\n",
    "$$\n",
    "Score = length(movies) \\times spearmancorr(Actual Rank, Recommened Rank)\n",
    "$$\n",
    "\n",
    "For each recommender system, we averaged score over all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "THjy6lnS32VM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank correlation test score for Collaborative Filtering Recommender: 4.66560622231\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained CF Recommender\n",
    "def CF_measure_auc(ratings_test, U, V):\n",
    "    \"\"\"for each user, measure the auc score on test data, return 1D array of AUC score\"\"\"\n",
    "    X_pred = U @ V.T\n",
    "    scores = []\n",
    "    lengths = []\n",
    "    for user_idx in range(ratings_test.shape[0]):\n",
    "        if np.count_nonzero(ratings_test[user_idx]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            movieidx = ratings_test[user_idx].nonzero()[0]\n",
    "            rating_true = ratings_test[user_idx, movieidx]\n",
    "            rating_pred = X_pred[user_idx, movieidx]\n",
    "            if np.unique(rating_true).size == 1 or np.unique(rating_pred).size == 1 :\n",
    "                continue\n",
    "            else:\n",
    "                scores.append(len(rating_true) * stats.spearmanr(rating_true, rating_pred)[0])\n",
    "    return scores\n",
    "\n",
    "CF_corr_scores = CF_measure_auc(ratings_test, trained_U, trained_V)\n",
    "print('The rank correlation test score for Collaborative Filtering Recommender:', np.mean(CF_corr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nEST-PEU4dMV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank correlation test score for Content-based Recommender: 4.84261883379\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained CB Recommender\n",
    "def CB_measure_auc(ratings_test, ratings_train, movies):\n",
    "    \"\"\"for each user, measure the auc score on test data, return 1D array of AUC score\"\"\"\n",
    "    scores = []\n",
    "    lengths = []\n",
    "    for user_idx in range(ratings_test.shape[0]):\n",
    "        if np.count_nonzero(ratings_test[user_idx]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            movieidx = ratings_test[user_idx].nonzero()[0]\n",
    "            rating_true = ratings_test[user_idx, movieidx]\n",
    "            rating_pred = predict_1user_movies(user_idx, movieidx, movies, ratings_train)\n",
    "            if np.unique(rating_true).size == 1 or np.unique(rating_pred).size == 1:\n",
    "                continue\n",
    "            else:\n",
    "                scores.append(len(rating_true) * stats.spearmanr(rating_true, rating_pred)[0])\n",
    "            \n",
    "    return scores\n",
    "  \n",
    "CB_corr_scores = CB_measure_auc(ratings_test, ratings_train, movies)\n",
    "print('The rank correlation test score for Content-based Recommender:', np.mean(CB_corr_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6QGsPwr3iukz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank correlation test score for Hybrid Recommender:  5.50112737795\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained LightFM model\n",
    "def FM_measure_auc(ratings_test):\n",
    "    \"\"\"for each user, measure the auc score on test data, return 1D array of AUC score\"\"\"\n",
    "    scores = []\n",
    "    lengths = []\n",
    "    for user_idx in range(ratings_test.shape[0]):\n",
    "        if np.count_nonzero(ratings_test[user_idx]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            movieidx = ratings_test[user_idx].nonzero()[1]\n",
    "            rating_true = np.array(ratings_test[user_idx, movieidx])[0]\n",
    "            rating_pred = model.predict(user_idx, movieidx, item_features=item_features_fm, num_threads=2)\n",
    "            if np.unique(rating_true).size == 1 or np.unique(rating_pred).size == 1 :\n",
    "                continue\n",
    "            else:\n",
    "                scores.append(len(rating_true) * stats.spearmanr(rating_true, rating_pred)[0])\n",
    "    return scores\n",
    "\n",
    "FM_corr_scores = FM_measure_auc(interaction_test.todense())\n",
    "print(\"The rank correlation test score for Hybrid Recommender: \", np.mean(FM_corr_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XO9Ydwe3lnTq"
   },
   "source": [
    "| | CF | CB | Hybrid |\n",
    "|:- :| |:----:|:----:|:----:|\n",
    "|Test Score |4.67| 4.84 | 5.46|\n",
    "\n",
    "\n",
    "The results of rank correlation test scores are summarized in the table above. As we can see, content-based model achieves a slightly better score than collaborative filtering model. The hybrid model we built outperforms both CF and CB, yielding a better ranking quality regarding recommendation list. \n",
    "\n",
    "In our project, we only used a medium size of user-item interaction data, which leads to the sparsity and therefore a relatively poor performance of collaborative filtering. With more dense interaction data, we capture more collaborative information about users' preferences and expect CF to have a better performance in such settings. However, in most real-life cases, we usually cannot expect to have enough data to make effective CF-based recommendations. That's when we want to incorporate content-based strategy and utilize item metadata to make more informed decisions. The hybrid model takes the advantage of both CF and CB, so it is not really surprising to see it achieves the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUO2gyhngknb"
   },
   "source": [
    "## Additional (Interesting) Facts\n",
    "With features of all the movies and ratings from the users, our content-based recommender can also find out what features are mostly loved by our users. Would your favourite actors be one of the beloved features? Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2072,
     "status": "ok",
     "timestamp": 1526073125496,
     "user": {
      "displayName": "Xiang Li",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111719387879022018839"
     },
     "user_tz": 240
    },
    "id": "if5gnoVT-Es6",
    "outputId": "ee04382d-7697-43c1-9c91-2f1f35c55a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 beloved movie features:\n",
      "['drama', 'cult_film', 'based_on_novel', 'crime', 'history', 'war', '1940s', 'nazi', 'harrison_ford', 'documentary']\n"
     ]
    }
   ],
   "source": [
    "overall_user_profile = np.zeros(item_features.shape[1])\n",
    "for userid in range(ratings_train.shape[0]):\n",
    "    overall_user_profile += get_1user_profile(userid, ratings_train, movies)[0]\n",
    "print('Top 10 beloved movie features:')\n",
    "print( [movie_features[idx] for idx in np.argsort(overall_user_profile)[::-1][:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7W2PdtEB22M"
   },
   "source": [
    "Among all the movie features, drama is the most popular genre. Surprisingly, cult film is the second feature in the list. It's probably because cult films have very specific audience target. Only those who love to watch cult film will rate cult film. Harrison Ford is probably the most popular actors due to his starring roles as Han Solo in the Star Wars film series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vH0p2PBC-a9i"
   },
   "source": [
    "## Citation\n",
    "[1] PyDataTV. “Maciej Kula - Hybrid Recommender Systems in Python.” YouTube, YouTube, 26 Mar. 2016, www.youtube.com/watch?v=EgE0DUrYmo8.  \n",
    "[2] Leskovec, Jure, Anand Rajaraman, and Jeffrey David Ullman. Mining of massive datasets. Cambridge university press, 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUO2gyhngknb"
   },
   "source": [
    "## Appendix\n",
    "\n",
    "### Script for Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of movies: 45843\n"
     ]
    }
   ],
   "source": [
    "# data import\n",
    "\n",
    "data_path = \"../Data/ml-latest/\"\n",
    "\n",
    "mov_links_df = pd.read_csv(data_path + \"links.csv\", dtype='str')\n",
    "print(\"num of movies: \" + str(mov_links_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mov_noTMDB_df = mov_links_df[mov_links_df[\"tmdbId\"].isna()]\n",
    "mov_withTMDB_df = mov_links_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of duplicated tmdbID: 29\n"
     ]
    }
   ],
   "source": [
    "dup_ids = set(mov_withTMDB_df[mov_withTMDB_df[\"tmdbId\"].duplicated() == True][\"tmdbId\"])\n",
    "print(\"num of duplicated tmdbID: \" + str(len(dup_ids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of rows using imdbID: 278\n",
      "num of rows using tmdbID: 45565\n"
     ]
    }
   ],
   "source": [
    "mov_dupTMDB_df = mov_withTMDB_df[mov_withTMDB_df[\"tmdbId\"].apply(lambda x:x in dup_ids)]\n",
    "mov_IMDB_df = pd.concat([mov_dupTMDB_df, mov_noTMDB_df])\n",
    "mov_TMDB_df = mov_withTMDB_df[mov_withTMDB_df[\"tmdbId\"].apply(lambda x:x not in dup_ids)]\n",
    "\n",
    "print(\"num of rows using imdbID: \" + str(mov_IMDB_df.shape[0]))\n",
    "print(\"num of rows using tmdbID: \" + str(mov_TMDB_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping from tmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {}\n",
    "error_log = []\n",
    "\n",
    "mov_TMDB_id_list = mov_TMDB_df[\"tmdbId\"]\n",
    "mov_TMDB_err_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scraping original html\n",
    "\n",
    "counter = 0\n",
    "for tmdb_id in mov_TMDB_id_list:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(\"[PROGRESS] {} / {}\".format(counter, len(mov_TMDB_id_list)))\n",
    "\n",
    "    url = \"https://www.themoviedb.org/movie/\" + tmdb_id\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"    [ERROR LOG] TMDB_ID: {}, Response Code: {}. Drop.\".format(tmdb_id, response.status_code))\n",
    "        error_log.append(\"    [ERROR LOG] TMDB_ID: {}, Response Code: {}. Drop.\".format(tmdb_id, response.status_code))\n",
    "        mov_TMDB_err_list.append(tmdb_id)\n",
    "    else:\n",
    "        response_dict[tmdb_id] = response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45100\n"
     ]
    }
   ],
   "source": [
    "print(len(response_dict))\n",
    "\n",
    "tmp_response_list = list(response_dict.items())\n",
    "\n",
    "with open('response_dict_1.p', 'wb') as fp:\n",
    "    pickle.dump(tmp_response_list[:20000], fp)\n",
    "\n",
    "with open('response_dict_2.p', 'wb') as fp:\n",
    "    pickle.dump(tmp_response_list[20000:40000], fp)\n",
    "\n",
    "with open('response_dict_3.p', 'wb') as fp:\n",
    "    pickle.dump(tmp_response_list[40000:], fp)\n",
    "\n",
    "# with open('scraping_error_log.p', 'wb') as fp:\n",
    "#     pickle.dump(error_log, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmp_response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('response_dict.p', 'rb') as fp:\n",
    "#     loaded_response_dict = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of mov_TMDB_valid_list: 45100\n",
      "length of response_dict: 45100\n",
      "difference between the two: \n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "err_id_set = set(mov_TMDB_err_list)\n",
    "mov_TMDB_valid_list = [tmdb_id for tmdb_id in mov_TMDB_id_list if tmdb_id not in err_id_set]\n",
    "\n",
    "# check the mov_TMDB_valid_list == response_dict.keys()\n",
    "print(\"length of mov_TMDB_valid_list: {}\".format(len(mov_TMDB_valid_list)))\n",
    "print(\"length of response_dict: {}\".format(len(list(response_dict.keys()))))\n",
    "print(\"difference between the two: \")\n",
    "print(set(mov_TMDB_valid_list) - set(list(response_dict.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movie_content = []\n",
    "mov_TMDB_final_list = []\n",
    "\n",
    "counter = 0\n",
    "for tmdb_id in mov_TMDB_valid_list:\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(\"[PROGRESS] {} / {}\".format(counter, len(mov_TMDB_valid_list)))\n",
    "\n",
    "    try:\n",
    "        html_text = response_dict[tmdb_id].text\n",
    "        root = BeautifulSoup(html_text, \"html.parser\")\n",
    "        mov_name = root.find(\"div\", class_=\"title\").span.a.h2.string\n",
    "\n",
    "        mov_lang = \"\"\n",
    "        mov_genres = []\n",
    "        mov_keywords = []\n",
    "        mov_crew = []\n",
    "        mov_actors = []\n",
    "        mov_infos = []\n",
    "\n",
    "        mov_facts = root.find(\"section\", class_=\"facts\").find_all(\"p\")\n",
    "        for fact in mov_facts:\n",
    "            if fact.bdi != None and fact.bdi.string == \"Original Language\":\n",
    "                mov_lang = re.sub(r\"[,.;@#?!&$ ]+\", \"_\", fact.contents[1].strip().lower())\n",
    "                mov_infos.append(mov_lang)\n",
    "\n",
    "        mov_genres_section = root.find(\"section\", class_=\"genres\").find_all(\"li\")\n",
    "        for genre in mov_genres_section:\n",
    "            mov_genres.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", genre.a.string.strip().lower()))\n",
    "        mov_infos.extend(mov_genres)\n",
    "\n",
    "        mov_keywords_section = root.find(\"section\", class_=\"keywords\").find_all(\"li\")\n",
    "        for keyword in mov_keywords_section:\n",
    "            mov_keywords.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", keyword.a.string.strip().lower()))\n",
    "        mov_infos.extend(mov_keywords)\n",
    "\n",
    "        mov_people_list = root.find(\"div\", class_=\"header_info\").find(\"ol\", class_=\"people\").find_all(\"a\")\n",
    "        for people in mov_people_list:\n",
    "            mov_crew.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", people.string.strip().lower()))\n",
    "        mov_infos.extend(mov_crew)\n",
    "\n",
    "        mov_actor_list = root.find(\"section\", class_=\"top_billed\").find_all(\"li\")\n",
    "        for actor in mov_actor_list:\n",
    "            mov_actors.append(re.sub(r\"[,.;@#?!&$ ]+\", \"_\", actor.p.a.string.strip().lower()))\n",
    "        mov_infos.extend(mov_actors)\n",
    "\n",
    "        movie_content.append(\" \".join(mov_infos))\n",
    "        mov_TMDB_final_list.append(tmdb_id)\n",
    "    except:\n",
    "        print(\"    [ERROR LOG] TMDB_ID: {}, unable to parse. Drop.\".format(tmdb_id))\n",
    "        mov_TMDB_err_list.append(tmdb_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_content.p', 'wb') as fp:\n",
    "    pickle.dump(movie_content, fp)\n",
    "\n",
    "with open('TMDB_final_list.p', 'wb') as fp:\n",
    "    pickle.dump(mov_TMDB_final_list, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2)\n",
    "item_features = tfidf.fit_transform(movie_content)\n",
    "item_features_dict = tfidf.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "save_npz('item_features.npz', item_features)\n",
    "# load_npz('item_features.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_features matrix shape: \n",
      "(42908, 52255)\n",
      "52255\n"
     ]
    }
   ],
   "source": [
    "print(\"item_features matrix shape: \")\n",
    "print(item_features.shape)\n",
    "print(len(item_features_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features_labels\n",
    "item_features_labels = []\n",
    "for feature, pos in sorted(item_features_dict.items(), key=lambda x:x[1]):\n",
    "    item_features_labels.append(feature)\n",
    "\n",
    "with open('item_features_labels.p', 'wb') as fp:\n",
    "    pickle.dump(item_features_labels, fp)\n",
    "with open('item_features_dict.p', 'wb') as fp:\n",
    "    pickle.dump(item_features_dict, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Rating Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SMALL_DATASET = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of movies: 9125\n",
      "num of ratings: 100004\n"
     ]
    }
   ],
   "source": [
    "# data import\n",
    "\n",
    "if USE_SMALL_DATASET:\n",
    "    data_path = \"../Data/ml-latest-small/\"\n",
    "else:\n",
    "    data_path = \"../Data/ml-latest/\"\n",
    "\n",
    "mov_links_df = pd.read_csv(data_path + \"links.csv\", dtype='str')\n",
    "print(\"num of movies: \" + str(mov_links_df.shape[0]))\n",
    "\n",
    "ratings_df = pd.read_csv(data_path + \"ratings.csv\")\n",
    "print(\"num of ratings: \" + str(ratings_df.shape[0]))\n",
    "ratings_df[\"movieId\"] = ratings_df[\"movieId\"].astype(\"str\")\n",
    "ratings_df[\"userId\"] = ratings_df[\"userId\"].astype(\"str\")\n",
    "ratings_df.drop(\"timestamp\", axis=1, inplace=True)\n",
    "\n",
    "movie_df = pd.read_csv(data_path + \"movies.csv\", dtype='str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating tmdb_id -> movie_id mapping\n",
    "\n",
    "tmdb_to_movie_id = {}\n",
    "\n",
    "for index, row in mov_links_df.iterrows():\n",
    "    if (row[\"tmdbId\"] is not None):\n",
    "        tmdb_to_movie_id[row[\"tmdbId\"]] = row[\"movieId\"]\n",
    "\n",
    "small_tmdb_set = set(tmdb_to_movie_id.keys())\n",
    "        \n",
    "del mov_links_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movie_content.p\", \"rb\") as fp:\n",
    "    movie_content_large = pickle.load(fp)\n",
    "\n",
    "with open(\"TMDB_final_list.p\", \"rb\") as fp:\n",
    "    tmdb_id_list_large = pickle.load(fp)\n",
    "\n",
    "movie_id_list = []\n",
    "tmdb_id_list = []\n",
    "movie_content = []\n",
    "\n",
    "for index, tmdb_id in enumerate(tmdb_id_list_large):\n",
    "    if not tmdb_id in small_tmdb_set:\n",
    "        continue\n",
    "    tmdb_id_list.append(tmdb_id)\n",
    "    movie_id_list.append(tmdb_to_movie_id[tmdb_id])\n",
    "    movie_content.append(movie_content_large[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=2)\n",
    "item_features = tfidf.fit_transform(movie_content)\n",
    "item_features_dict = tfidf.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALL_DATASET:\n",
    "    save_npz('./small/item_features.npz', item_features)\n",
    "else:\n",
    "    save_npz('./item_features.npz', item_features)\n",
    "# load_npz('item_features.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_features_labels\n",
    "\n",
    "item_features_labels = []\n",
    "for feature, pos in sorted(item_features_dict.items(), key=lambda x:x[1]):\n",
    "    item_features_labels.append(feature)\n",
    "\n",
    "if USE_SMALL_DATASET:\n",
    "    with open('./small/item_features_labels.p', 'wb') as fp:\n",
    "        pickle.dump(item_features_labels, fp)\n",
    "    with open('./small/item_features_dict.p', 'wb') as fp:\n",
    "        pickle.dump(item_features_dict, fp)\n",
    "else:\n",
    "    with open('./item_features_labels.p', 'wb') as fp:\n",
    "        pickle.dump(item_features_labels, fp)\n",
    "    with open('./item_features_dict.p', 'wb') as fp:\n",
    "        pickle.dump(item_features_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the movie list (in order) used in the item_features matrix\n",
    "\n",
    "movie_id_set = set(movie_id_list)\n",
    "movie_id_dict = {movie_id:i for i, movie_id in enumerate(movie_id_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only leave records that have a corresponding movie record\n",
    "\n",
    "sub_ratings = ratings_df[ratings_df[\"movieId\"].apply(lambda x:x in movie_id_set)]\n",
    "sub_ratings.reset_index(inplace=True)\n",
    "\n",
    "# del ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of movie_name: 8954\n"
     ]
    }
   ],
   "source": [
    "usr_list = sub_ratings[\"userId\"].unique()\n",
    "usr_dict = {userID : i for i, userID in enumerate(usr_list)}\n",
    "usr_num = len(usr_list)\n",
    "\n",
    "mov_list = movie_id_list\n",
    "mov_dict = movie_id_dict\n",
    "mov_num = len(mov_list)\n",
    "\n",
    "movie_names = [list(movie_df[movie_df['movieId'] == movie_id][\"title\"])[0] for movie_id in mov_list]\n",
    "\n",
    "print(\"length of movie_name: \" + str(len(movie_names)))\n",
    "\n",
    "del movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SMALL_DATASET:\n",
    "    with open('./small/item_labels.p', 'wb') as fp:\n",
    "        pickle.dump(movie_names, fp)\n",
    "else:\n",
    "    with open('./item_labels.p', 'wb') as fp:\n",
    "        pickle.dump(movie_names, fp)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set shape: \n",
      "(89580, 4)\n",
      "test set shape: \n",
      "(9954, 4)\n"
     ]
    }
   ],
   "source": [
    "# training and testing split\n",
    "P = np.random.permutation(len(sub_ratings))\n",
    "entry_num = len(P)\n",
    "train_num = int(np.floor(9 * entry_num / 10))\n",
    "train_set = sub_ratings.loc[P[:train_num]]\n",
    "test_set = sub_ratings.loc[P[train_num:]]\n",
    "\n",
    "print(\"train set shape: \")\n",
    "print(train_set.shape)\n",
    "\n",
    "print(\"test set shape: \")\n",
    "print(test_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sum and frequency for each people. For Normalization!!!\n",
    "user_rating_stat = {}\n",
    "\n",
    "for index, row in sub_ratings.iterrows():\n",
    "    user_id = row[\"userId\"]\n",
    "    if user_id in user_rating_stat:\n",
    "        user_rating_stat[user_id][\"ratings\"] += row[\"rating\"]\n",
    "        user_rating_stat[user_id][\"freq\"] += 1\n",
    "    else:\n",
    "        user_rating_stat[user_id] = {\"ratings\": row[\"rating\"], \"freq\": 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "# compute training matrix\n",
    "for index, row in train_set.iterrows():\n",
    "    counter += 1\n",
    "    if counter % 100000 == 0:\n",
    "        print(\"[PROGRESS] {} / {}\".format(counter, train_set.shape[0]))\n",
    "\n",
    "    rows.append(usr_dict[row[\"userId\"]])\n",
    "    cols.append(mov_dict[row[\"movieId\"]])\n",
    "    data.append(row[\"rating\"] - (user_rating_stat[row[\"userId\"]][\"ratings\"] / user_rating_stat[row[\"userId\"]][\"freq\"]))\n",
    "\n",
    "X_tr = coo_matrix((data, (rows, cols)), shape=(usr_num, mov_num))\n",
    "\n",
    "if USE_SMALL_DATASET:\n",
    "    save_npz('./small/interaction_train.npz', X_tr)\n",
    "else:\n",
    "    save_npz('./interaction_train.npz', X_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "# compute testing matrix\n",
    "for index, row in test_set.iterrows():\n",
    "    counter += 1\n",
    "    if counter % 100000 == 0:\n",
    "        print(\"[PROGRESS] {} / {}\".format(counter, test_set.shape[0]))\n",
    "\n",
    "    rows.append(usr_dict[row[\"userId\"]])\n",
    "    cols.append(mov_dict[row[\"movieId\"]])\n",
    "    data.append(row[\"rating\"] - (user_rating_stat[row[\"userId\"]][\"ratings\"] / user_rating_stat[row[\"userId\"]][\"freq\"]))\n",
    "\n",
    "X_te = coo_matrix((data, (rows, cols)), shape=(usr_num, mov_num))\n",
    "\n",
    "if USE_SMALL_DATASET:\n",
    "    save_npz('./small/interaction_test.npz', X_te)\n",
    "else:\n",
    "    save_npz('./interaction_test.npz', X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_features matrix shape: \n",
      "(8954, 16674)\n",
      "\n",
      "interaction matrix shape: \n",
      "(671, 8954)\n",
      "\n",
      "item_features_labels length: \n",
      "16674\n",
      "\n",
      "item_labels length: \n",
      "8954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"item_features matrix shape: \")\n",
    "print(item_features.shape)\n",
    "print()\n",
    "print(\"interaction matrix shape: \")\n",
    "print(X_tr.shape)\n",
    "print()\n",
    "print(\"item_features_labels length: \")\n",
    "print(len(item_features_labels))\n",
    "print()\n",
    "print(\"item_labels length: \")\n",
    "print(len(movie_names))\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "PDS Project Recommender System.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
